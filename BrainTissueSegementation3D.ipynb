{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os, glob, random, sys, time, keras, cv2, itertools, sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing import image\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.utils.fixes import signature\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.engine import Input, Model\n",
    "from keras.layers import Conv3D, MaxPooling3D, UpSampling3D, Activation, BatchNormalization, PReLU, Deconvolution3D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from metrics import dice_coefficient_loss, get_label_dice_coefficient_function, dice_coefficient\n",
    "\n",
    "K.set_image_data_format(\"channels_first\")\n",
    "\n",
    "try:\n",
    "    from keras.engine import merge\n",
    "except ImportError:\n",
    "    from keras.layers.merge import concatenate\n",
    "\n",
    "\n",
    "def unet_model_3d(input_shape, pool_size=(2, 2, 2), n_labels=1, initial_learning_rate=0.00001, deconvolution=False,\n",
    "                  depth=4, n_base_filters=32, include_label_wise_dice_coefficients=False, metrics=dice_coefficient,\n",
    "                  batch_normalization=False, activation_name=\"sigmoid\"):\n",
    "    \"\"\"\n",
    "    Builds the 3D UNet Keras model.f\n",
    "    :param metrics: List metrics to be calculated during model training (default is dice coefficient).\n",
    "    :param include_label_wise_dice_coefficients: If True and n_labels is greater than 1, model will report the dice\n",
    "    coefficient for each label as metric.\n",
    "    :param n_base_filters: The number of filters that the first layer in the convolution network will have. Following\n",
    "    layers will contain a multiple of this number. Lowering this number will likely reduce the amount of memory required\n",
    "    to train the model.\n",
    "    :param depth: indicates the depth of the U-shape for the model. The greater the depth, the more max pooling\n",
    "    layers will be added to the model. Lowering the depth may reduce the amount of memory required for training.\n",
    "    :param input_shape: Shape of the input data (n_chanels, x_size, y_size, z_size). The x, y, and z sizes must be\n",
    "    divisible by the pool size to the power of the depth of the UNet, that is pool_size^depth.\n",
    "    :param pool_size: Pool size for the max pooling operations.\n",
    "    :param n_labels: Number of binary labels that the model is learning.\n",
    "    :param initial_learning_rate: Initial learning rate for the model. This will be decayed during training.\n",
    "    :param deconvolution: If set to True, will use transpose convolution(deconvolution) instead of up-sampling. This\n",
    "    increases the amount memory required during training.\n",
    "    :return: Untrained 3D UNet Model\n",
    "    \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "    current_layer = inputs\n",
    "    levels = list()\n",
    "\n",
    "    # add levels with max pooling\n",
    "    for layer_depth in range(depth):\n",
    "        layer1 = create_convolution_block(input_layer=current_layer, n_filters=n_base_filters*(2**layer_depth),\n",
    "                                          batch_normalization=batch_normalization)\n",
    "        layer2 = create_convolution_block(input_layer=layer1, n_filters=n_base_filters*(2**layer_depth)*2,\n",
    "                                          batch_normalization=batch_normalization)\n",
    "        if layer_depth < depth - 1:\n",
    "            current_layer = MaxPooling3D(pool_size=pool_size)(layer2)\n",
    "            levels.append([layer1, layer2, current_layer])\n",
    "        else:\n",
    "            current_layer = layer2\n",
    "            levels.append([layer1, layer2])\n",
    "\n",
    "    # add levels with up-convolution or up-sampling\n",
    "    for layer_depth in range(depth-2, -1, -1):\n",
    "        up_convolution = get_up_convolution(pool_size=pool_size, deconvolution=deconvolution,\n",
    "                                            n_filters=current_layer._keras_shape[1])(current_layer)\n",
    "        concat = concatenate([up_convolution, levels[layer_depth][1]], axis=1)\n",
    "        current_layer = create_convolution_block(n_filters=levels[layer_depth][1]._keras_shape[1],\n",
    "                                                 input_layer=concat, batch_normalization=batch_normalization)\n",
    "        current_layer = create_convolution_block(n_filters=levels[layer_depth][1]._keras_shape[1],\n",
    "                                                 input_layer=current_layer,\n",
    "                                                 batch_normalization=batch_normalization)\n",
    "\n",
    "    final_convolution = Conv3D(n_labels, (1, 1, 1))(current_layer)\n",
    "    act = Activation(activation_name)(final_convolution)\n",
    "    model = Model(inputs=inputs, outputs=act)\n",
    "\n",
    "    if not isinstance(metrics, list):\n",
    "        metrics = [metrics]\n",
    "\n",
    "    if include_label_wise_dice_coefficients and n_labels > 1:\n",
    "        label_wise_dice_metrics = [get_label_dice_coefficient_function(index) for index in range(n_labels)]\n",
    "        if metrics:\n",
    "            metrics = metrics + label_wise_dice_metrics\n",
    "        else:\n",
    "            metrics = label_wise_dice_metrics\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=initial_learning_rate), loss=dice_coefficient_loss, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_convolution_block(input_layer, n_filters, batch_normalization=False, kernel=(3, 3, 3), activation=None,\n",
    "                             padding='same', strides=(1, 1, 1), instance_normalization=False):\n",
    "    \"\"\"\n",
    "\n",
    "    :param strides:\n",
    "    :param input_layer:\n",
    "    :param n_filters:\n",
    "    :param batch_normalization:\n",
    "    :param kernel:\n",
    "    :param activation: Keras activation layer to use. (default is 'relu')\n",
    "    :param padding:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    layer = Conv3D(n_filters, kernel, padding=padding, strides=strides)(input_layer)\n",
    "    if batch_normalization:\n",
    "        layer = BatchNormalization(axis=1)(layer)\n",
    "    elif instance_normalization:\n",
    "        try:\n",
    "            from keras_contrib.layers.normalization import InstanceNormalization\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Install keras_contrib in order to use instance normalization.\"\n",
    "                              \"\\nTry: pip install git+https://www.github.com/farizrahman4u/keras-contrib.git\")\n",
    "        layer = InstanceNormalization(axis=1)(layer)\n",
    "    if activation is None:\n",
    "        return Activation('relu')(layer)\n",
    "    else:\n",
    "        return activation()(layer)\n",
    "\n",
    "\n",
    "def compute_level_output_shape(n_filters, depth, pool_size, image_shape):\n",
    "    \"\"\"\n",
    "    Each level has a particular output shape based on the number of filters used in that level and the depth or number \n",
    "    of max pooling operations that have been done on the data at that point.\n",
    "    :param image_shape: shape of the 3d image.\n",
    "    :param pool_size: the pool_size parameter used in the max pooling operation.\n",
    "    :param n_filters: Number of filters used by the last node in a given level.\n",
    "    :param depth: The number of levels down in the U-shaped model a given node is.\n",
    "    :return: 5D vector of the shape of the output node \n",
    "    \"\"\"\n",
    "    output_image_shape = np.asarray(np.divide(image_shape, np.power(pool_size, depth)), dtype=np.int32).tolist()\n",
    "    return tuple([None, n_filters] + output_image_shape)\n",
    "\n",
    "\n",
    "def get_up_convolution(n_filters, pool_size, kernel_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                       deconvolution=False):\n",
    "    if deconvolution:\n",
    "        return Deconvolution3D(filters=n_filters, kernel_size=kernel_size,\n",
    "                               strides=strides)\n",
    "    else:\n",
    "        return UpSampling3D(size=pool_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-943f68326936>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwrite_data_to_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen_data_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_training_and_validation_generators\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0munet_model_3d\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\3D-Semantic-Segmentation-for-the-Brain-Tissue-Segmentation\\data.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnormalize_data_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreslice_image_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "from data import write_data_to_file, open_data_file\n",
    "from generator import get_training_and_validation_generators\n",
    "from model import unet_model_3d\n",
    "from training import load_old_model, train_model\n",
    "\n",
    "\n",
    "config = dict()\n",
    "config[\"pool_size\"] = (2, 2, 2)  # pool size for the max pooling operations\n",
    "config[\"image_shape\"] = (144, 144, 144)  # This determines what shape the images will be cropped/resampled to.\n",
    "config[\"patch_shape\"] = (64, 64, 64)  # switch to None to train on the whole image\n",
    "config[\"labels\"] = (1, 2, 4)  # the label numbers on the input image\n",
    "config[\"n_labels\"] = len(config[\"labels\"])\n",
    "config[\"all_modalities\"] = [\"t1\", \"t1ce\", \"flair\", \"t2\"]\n",
    "config[\"training_modalities\"] = config[\"all_modalities\"]  # change this if you want to only use some of the modalities\n",
    "config[\"nb_channels\"] = len(config[\"training_modalities\"])\n",
    "if \"patch_shape\" in config and config[\"patch_shape\"] is not None:\n",
    "    config[\"input_shape\"] = tuple([config[\"nb_channels\"]] + list(config[\"patch_shape\"]))\n",
    "else:\n",
    "    config[\"input_shape\"] = tuple([config[\"nb_channels\"]] + list(config[\"image_shape\"]))\n",
    "config[\"truth_channel\"] = config[\"nb_channels\"]\n",
    "config[\"deconvolution\"] = True  # if False, will use upsampling instead of deconvolution\n",
    "\n",
    "config[\"batch_size\"] = 6\n",
    "config[\"validation_batch_size\"] = 12\n",
    "config[\"n_epochs\"] = 500  # cutoff the training after this many epochs\n",
    "config[\"patience\"] = 10  # learning rate will be reduced after this many epochs if the validation loss is not improving\n",
    "config[\"early_stop\"] = 50  # training will be stopped after this many epochs without the validation loss improving\n",
    "config[\"initial_learning_rate\"] = 0.00001\n",
    "config[\"learning_rate_drop\"] = 0.5  # factor by which the learning rate will be reduced\n",
    "config[\"validation_split\"] = 0.8  # portion of the data that will be used for training\n",
    "config[\"flip\"] = False  # augments the data by randomly flipping an axis during\n",
    "config[\"permute\"] = True  # data shape must be a cube. Augments the data by permuting in various directions\n",
    "config[\"distort\"] = None  # switch to None if you want no distortion\n",
    "config[\"augment\"] = config[\"flip\"] or config[\"distort\"]\n",
    "config[\"validation_patch_overlap\"] = 0  # if > 0, during training, validation patches will be overlapping\n",
    "config[\"training_patch_start_offset\"] = (16, 16, 16)  # randomly offset the first patch index by up to this offset\n",
    "config[\"skip_blank\"] = True  # if True, then patches without any target will be skipped\n",
    "\n",
    "config[\"data_file\"] = os.path.abspath(\"brats_data.h5\")\n",
    "config[\"model_file\"] = os.path.abspath(\"tumor_segmentation_model.h5\")\n",
    "config[\"training_file\"] = os.path.abspath(\"training_ids.pkl\")\n",
    "config[\"validation_file\"] = os.path.abspath(\"validation_ids.pkl\")\n",
    "config[\"overwrite\"] = False  # If True, will previous files. If False, will use previously written files.\n",
    "\n",
    "\n",
    "def fetch_training_data_files():\n",
    "    training_data_files = list()\n",
    "    for subject_dir in glob.glob(os.path.join(os.path.dirname(__file__), \"data\", \"preprocessed\", \"*\", \"*\")):\n",
    "        subject_files = list()\n",
    "        for modality in config[\"training_modalities\"] + [\"truth\"]:\n",
    "            subject_files.append(os.path.join(subject_dir, modality + \".nii.gz\"))\n",
    "        training_data_files.append(tuple(subject_files))\n",
    "    return training_data_files\n",
    "\n",
    "\n",
    "def main(overwrite=False):\n",
    "    # convert input images into an hdf5 file\n",
    "    if overwrite or not os.path.exists(config[\"data_file\"]):\n",
    "        training_files = fetch_training_data_files()\n",
    "\n",
    "        write_data_to_file(training_files, config[\"data_file\"], image_shape=config[\"image_shape\"])\n",
    "    data_file_opened = open_data_file(config[\"data_file\"])\n",
    "\n",
    "    if not overwrite and os.path.exists(config[\"model_file\"]):\n",
    "        model = load_old_model(config[\"model_file\"])\n",
    "    else:\n",
    "        # instantiate new model\n",
    "        model = unet_model_3d(input_shape=config[\"input_shape\"],\n",
    "                              pool_size=config[\"pool_size\"],\n",
    "                              n_labels=config[\"n_labels\"],\n",
    "                              initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "                              deconvolution=config[\"deconvolution\"])\n",
    "\n",
    "    # get training and testing generators\n",
    "    train_generator, validation_generator, n_train_steps, n_validation_steps = get_training_and_validation_generators(\n",
    "        data_file_opened,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        data_split=config[\"validation_split\"],\n",
    "        overwrite=overwrite,\n",
    "        validation_keys_file=config[\"validation_file\"],\n",
    "        training_keys_file=config[\"training_file\"],\n",
    "        n_labels=config[\"n_labels\"],\n",
    "        labels=config[\"labels\"],\n",
    "        patch_shape=config[\"patch_shape\"],\n",
    "        validation_batch_size=config[\"validation_batch_size\"],\n",
    "        validation_patch_overlap=config[\"validation_patch_overlap\"],\n",
    "        training_patch_start_offset=config[\"training_patch_start_offset\"],\n",
    "        permute=config[\"permute\"],\n",
    "        augment=config[\"augment\"],\n",
    "        skip_blank=config[\"skip_blank\"],\n",
    "        augment_flip=config[\"flip\"],\n",
    "        augment_distortion_factor=config[\"distort\"])\n",
    "\n",
    "    # run training\n",
    "    train_model(model=model,\n",
    "                model_file=config[\"model_file\"],\n",
    "                training_generator=train_generator,\n",
    "                validation_generator=validation_generator,\n",
    "                steps_per_epoch=n_train_steps,\n",
    "                validation_steps=n_validation_steps,\n",
    "                initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "                learning_rate_drop=config[\"learning_rate_drop\"],\n",
    "                learning_rate_patience=config[\"patience\"],\n",
    "                early_stopping_patience=config[\"early_stop\"],\n",
    "                n_epochs=config[\"n_epochs\"])\n",
    "    data_file_opened.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(overwrite=config[\"overwrite\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
